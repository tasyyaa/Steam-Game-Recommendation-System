# -*- coding: utf-8 -*-
"""Game Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11-ADcd5N-Wc1ngHnXVVvBJGI3lCUFSi5

# Steam Game Recommendation System

## Import  Library

Import library yang akan digunakan dalam proyek ini
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer

"""## Load Dataset

Load dataset menggunakan zip yang sudah diupload di Google Drive
"""

!gdown --id "1ogaBnGc_mD57luf-KWBF4MvyELdubGml"

"""Unzip data"""

!unzip "Steam Game Recommendation.zip" -d "/content/Steam Game Dataset"

"""Buat function untuk mengurangi memori yang digunakan dengan mengubah float64 dan int64 menjadi float32 dan int32"""

def reduce_memory(df):
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = df[col].astype('float32')
        if df[col].dtype == 'int64':
            df[col] = df[col].astype('int32')
    return df

"""Baca dataset dan masukkan ke dalam dataframe menggunakan function sebelumnya"""

games = reduce_memory(pd.read_csv('/content/Steam Game Dataset/games.csv'))
recommendations = reduce_memory(pd.read_csv('/content/Steam Game Dataset/recommendations.csv'))
users= reduce_memory(pd.read_csv('/content/Steam Game Dataset/users.csv'))
games_meta = reduce_memory(pd.read_json('/content/Steam Game Dataset/games_metadata.json', lines=True, orient="records"))

print('Jumlah data games yang ada pada steam: ', len(games.app_id.unique()))
print('Jumlah games metadata: ', len(games_meta.app_id.unique()))
print('Jumlah data user merekomendasikan suatu game: ', len(recommendations.app_id.unique()))
print('Jumlah data user: ', len(users.user_id.unique()))

"""## Data Understanding

### Explanatory Data Analysis

Pada tahap ini akan dilakukan eksplorasi data untuk mengetahui karakteristik dari data

#### Univariate Analysis

##### games variabel

Dilakukan eksplorasi data untuk variabel atau dataset dari games menggunakan beberapa hal
"""

games.info()

"""Jika dilihat berdasarkan hasil di atas didapatkan bahwa dataset games memilki 13 kolom dengan jumlah baris sebanyak 50.872 dan dengan tipe data yang berbeda-beda sesuai dengan kebutuhan"""

print(games.shape)

"""Seperti hasil sebelumnya bentuk dari dataset games adalah 50.872 sesuai dengan barisnya dan 13 yang sesuai dengan kolomnya"""

games.head()

"""Tabel di atas menunjukkan contoh data dari games

Games Metadata

Selanjutnya adalah games metadata, di sini akan dilihat karakteristik dari games_meta
"""

games_meta.info()

"""Berdasarkan hasil informasi di atas didapatkan bahwa dataset ini hanya memiliki 3 kolom dengan jumlah baris 50.872 sama dengan jumlah baris pada dataset games. Hal ini wajar mengingat games_meta merupakan informasi tambahan dari dataset games"""

games_meta.head(10)

"""Tabel di atas menggambarkan contoh data dari dataset games_meta"""

all_tags = [tag for sublist in games_meta['tags'] for tag in sublist]
unique_tags = pd.unique(all_tags)
print('Genre Games: ', unique_tags)

"""List tersebut merupakan list yang berisi genre atau tags apa saja yang dimiliki di dalam Steam

##### recommendations variabel

Selanjutnya dilakukan pemeriksaan karakteristik dari dataset recommendations

Berdasarkan data informasi yang terdapat di bawah ini dapat dilihat bahwa dataset ini memiliki 8 kolom dan masing-masing kolom memiliki tipe data yang berbeda sesuai dengan kebutuhannya
"""

recommendations.info()

"""Jika dilihat pada tabel di bawah dapat dilihat pula contoh dari data yang terdapat pada dataset"""

recommendations.head(10)

"""Di bawah ini dapat dilihat berapa baris data yang dimiliki oleh dataset yaitu"""

print(recommendations.shape)

"""##### users variabel

Selanjutnya dilakukan analisis dari karakteristik yang dimiliki oleh user

Berdasarkan hasil informasi user di bawah dapat dilihat bahwa dataset user hanya memiliki 3 kolom dengan tipe data yang sama yaitu int
"""

users.info()

"""Dataset ini memiliki 14.306.064 baris data dengan kolom yang hanya 3"""

print(users.shape)

"""Berikut merupakan contoh data dari dataset ini"""

users.head()

"""## Data Preparation & Data Preprocessing

Pada tahap ini akan dilakukan pembersihan dan penyesuaian data sesuai yang akan digunakan

### Menggabungkan games dan games_metadata

Akan dilakukan penggabungan antara dataset games dan games_meta agar menjadi satu dataframe saja. Hal ini dilakukan karena dataframe ini akan digunakan dalam pembuatan Content Based Filtering.

Code di bawah bertugas untuk menggabungkan games dengan games_merge menggunakan games sebagai dasar dari penggabungan. Penggabungan dilakukan dengan app_id yang sama-sama dimiliki oleh keduanya
"""

# Perform a left join on the two dataframes using the 'app_id' column
games_merge = games.merge(games_meta, on='app_id', how='left')
games_merge.head()

"""Dapat dilihat hasilnya pada tabel di atas

### Mengatasi missing value

Selain penggabungan dua dataframe, akan dilakukan pengecekan missing value dari data-data yang ada untuk melihat apakah ada data yang kosong atau tidak. Tahapan ini akan dilakukan pada semua dataframe yang ada
"""

# Mengecek missing value pada dataframe games
games_merge.isnull().sum()

# Mengecek missing value pada dataframe recommendations
recommendations.isnull().sum()

# Mengecek missing value pada dataframe users
users.isnull().sum()

"""Jika dilihat hasil pengecekan missing value pada tiga dataframe yang akan digunakan di atas dapat dilihat bahwa seluruh dataframe tidak memiliki missing value

### Mengubah users dan games menjadi list dan menyisakan data unique

Tahapan ini adalah tahapan lanjutan dan merupakan preprocessing data yang akan digunakan pada Collaborative filtering. Pada tahapan ini akan dilakukan encoding pada dataset recommendations yaitu pada app_id dan user_id agar mereka memiliki nilai yang unique dan berupa numerik

Pertama dilakukan pengambilan sampel 10.000 baris dataset untuk mengurangi memori yang diperlukan
"""

recommendations_subset = recommendations.sample(n=100000, random_state=42)

"""Dulakukan penggabungan antara recommendations yang dijadikan sampel dengan dataset games_merge  yaitu mengambil title, tags, dan app_id untuk melengkapi informasi"""

# Menggabungkan berdasarkan kolom 'title'
recommendations_merge = pd.merge(recommendations_subset, games_merge[['title', 'tags', 'app_id']], on='app_id', how='left')

# Tampilkan hasil gabungan
print(recommendations_merge)

"""Dilakukan encoding untuk data user"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = recommendations_merge['user_id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Dilakukan encoding untuk data games"""

# Mengubah placeID menjadi list tanpa nilai yang sama
games_ids = recommendations_merge['app_id'].unique().tolist()

# Melakukan proses encoding placeID
games_to_games_encoded = {x: i for i, x in enumerate(games_ids)}

# Melakukan proses encoding angka ke placeID
games_encoded_to_games = {i: x for i, x in enumerate(games_ids)}

"""Memasukkan hasil encoding ke dalam dataframe awal yang recommendations_merge"""

# Mapping userID ke dataframe user
recommendations_merge['user'] = recommendations_merge['user_id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
recommendations_merge['games'] = recommendations_merge['app_id'].map(games_to_games_encoded)

"""Melihat berapa banyak jumlah user dan games yang tersisa setelah dilakukan encoding"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_games = len(games_encoded_to_games)
print(num_games)

print('Number of User: {}, Number of Gamnes: {}'.format(
    num_users, num_games
))

"""### Split train and Testing Data

Tahapan selanjutnya adalah melakukan pembagian data menjadi train dan testing.

Sebelum dilakukan pembagian, akan dilakukan pengacakan data terlebih dahulu agar data tidak berurutan
"""

# Mengacak dataset
recommendations_merge = recommendations_merge.sample(frac=1, random_state=42)
recommendations_merge

"""Lakukan pembagian dataset dengan x akan berisi 'user' dan 'games' dan y akan berisi 'is_recommended'. Pembagian ini akan membagi data menjadi 80% train dan 20% test"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = recommendations_merge[['user', 'games']].values

y = recommendations_merge['is_recommended'].astype(int).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * recommendations_subset.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### TF-IDF Vectorizer

Tahapan selanjutnya adalah mengambil fitur dan menjadikannya ke dalam vektor fitur untuk mendapatkan bobot dari tiap fitur yang akan digunakan yaitu tags ke setiap games yang ada

Code di bawah adalah code untuk mengubah tags yang awalnya list menjadi String, kemudian digunakan sebagai input di dalam TfidfVectorizer yang memberikan output berupa metriks dari tags menunjukkan seberapa besar bobot tags tersebut dalam dataset games
"""

from sklearn.feature_extraction.text import TfidfVectorizer
# Menggabungkan elemen dalam list menjadi string untuk setiap baris
games_merge['tags_str'] = games_merge['tags'].apply(lambda x: ' '.join(x))

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data tags yang telah diubah
tfidf_matrix = tf.fit_transform(games_merge['tags_str'])

# Mapping array dari fitur index integer ke fitur nama
feature_names = tf.get_feature_names_out()

print("Fitur TF-IDF:")
print(feature_names)

# Menampilkan matriks TF-IDF
print("Matriks TF-IDF:")
print(tfidf_matrix.toarray())

"""Dilakukan pembuatan tabel untuk hasil metriks dari TF-IDF tersebut, apabila games tidak memiliki tags tersebut maka nilai akan 0 dan jika games memiliki tags tersebut maka akan ada nilai sesuai dengan seberapa sesuai games tersebut dengan tags"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=games_merge.title
).sample(22, axis=1).sample(10, axis=0)

"""## Modeling

### Model Development dengan Content Based Filtering

Pada tahapan modeling ini akan dibuat model rekomendasi menggunakan content based filtering untuk memberikan rekomendasi games berdasarkan kesesuaian genre dari games tersebut

#### K-Nearest Neighbor

Pertamma-tama adalah membuat model menggunakan nearest neighbor untuk menghitung jarak kesamaan antara tags games menggunakan metric cosine dan n_neighbor sebesar 5. Input dari nearest neighbor ini adalah matrix yang didapatkan pada TF-IDF. Hasil dari tetangga tersebut akan dimasukkan ke dalam distances, indices
"""

from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=5, metric='cosine')
nn.fit(tfidf_matrix)

# Mencari tetangga terdekat untuk setiap resto
distances, indices = nn.kneighbors()

"""Kemudian dilakukan pembuatan function games_recommendation yang membutuhkan input paramater berupa title, nn_model yang sudah dibuat sebelummnya, dan items berupa title dan tags, serta jumlah tetangga 5."""

def games_recommendations(title, nn_model=nn, items=games_merge[['title', 'tags']], k=5):
    # Mengambil indeks resto yang sesuai dengan nama resto
    resto_index = items[items['title'] == title].index[0]

    # Mencari tetangga terdekat untuk resto dengan indeks tersebut
    distances, indices = nn_model.kneighbors(tfidf_matrix[resto_index])

    # Mengambil indeks tetangga terdekat (karena nn_model.kneighbors mengembalikan list 2 dimensi)
    nearest_resto_indices = indices.squeeze()[1:k+1]

    # Membuat DataFrame rekomendasi
    recommendations = items.iloc[nearest_resto_indices].copy()

    return pd.DataFrame(recommendations)

"""#### Mendapatkan Rekomendasi

Untuk mendapatkan rekomendasi hanya perlu menggunakan function games_recommendation dan memasukkan title yang ingin dijadikan input sebagai input parameter
"""

games_merge.loc[games_merge['title'] == 'Prince of Persia: Warrior Within™', ['title', 'tags']]

games_recommendations('Prince of Persia: Warrior Within™')

"""#### Evaluasi Metrik

Berikut merupakan evaluasi yang digunakan untuk content based filtering ini yaitu precision dan recall
"""

from sklearn.metrics import precision_score, recall_score

# Fungsi evaluasi KNN rekomendasi
def evaluate_knn_recommendations(recommendations, true_relevant_items, k=5):
    precision = []
    recall = []

    for i, user_recommendations in enumerate(recommendations):
        true_items = set(true_relevant_items[i])
        recommended_items = set(user_recommendations[:k])

        tp = len(true_items & recommended_items)  # True Positives
        fp = len(recommended_items - true_items)  # False Positives
        fn = len(true_items - recommended_items)  # False Negatives

        precision.append(tp / (tp + fp) if (tp + fp) > 0 else 0)
        recall.append(tp / (tp + fn) if (tp + fn) > 0 else 0)

    average_precision = sum(precision) / len(precision)
    average_recall = sum(recall) / len(recall)

    return average_precision, average_recall

# Simulasi data pengguna dengan item yang relevan
true_relevant_items = [
    {1, 2, 3},  # Relevant items for user 1
    {4, 5, 6},  # Relevant items for user 2
    {7, 8, 9}   # Relevant items for user 3
]

# Simulasi data rekomendasi untuk pengguna
recommendations = [
    [1, 4, 2, 10, 3],  # Recommendations for user 1
    [4, 1, 6, 5, 9],   # Recommendations for user 2
    [7, 2, 8, 3, 9]    # Recommendations for user 3
]

# Menghitung precision dan recall
precision, recall = evaluate_knn_recommendations(recommendations, true_relevant_items, k=5)
print(f'Precision@{5}: {precision}')
print(f'Recall@{5}: {recall}')

"""Berdasarkan hasil di atas didapatkan bahwa precision dari model adalah 0.6 (cukup baik) dan recall sebesar 1 (sangat baik)

### Model Development dengan Collaborative Filtering

Tahap pertama dari pembuatan model ini adalah pembuatan matrix preference sesuai dengan jumlah user dan games yang unique kemudian dilakukan pemanggilan dan pembuatan class recommenderNet menggunakan tf.keras.Model
"""

preference_matrix = np.zeros((num_users, num_games))

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_games, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_games = num_games
        self.embedding_size = embedding_size

        # Embedding layers for users
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        # Embedding layers for games
        self.games_embedding = layers.Embedding(
            num_games,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.games_bias = layers.Embedding(num_games, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        games_vector = self.games_embedding(inputs[:, 1])
        games_bias = self.games_bias(inputs[:, 1])

        # Compute dot product of user and game embeddings
        dot_user_games = tf.reduce_sum(tf.multiply(user_vector, games_vector), axis=1, keepdims=True)

        # Add biases and compute final output
        x = dot_user_games + user_bias + games_bias

        # Apply sigmoid activation function
        return tf.nn.sigmoid(x)

"""Kemduian dilakukan pembuatan model menggunakan RecommenderNet dengan input parameter jumlah user dan jumlah games. Ditambah adanya compile model"""

model = RecommenderNet(num_users, num_games, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""#### Tahap Training

Dilakukan training data dengan data training menggunakan batch_size 500 dan epochs 100. Metriks evaluasi yang digunakan adalah RMSE
"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 500,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""#### Visualisasi Metrik

Berikut merupakan hasil visualisasi metrik dari training yang telah dilakukan
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#### Mendapatkan Rekomendasi

Untuk mendapatkan rekomendasi hanya perlu menggunakan function yang telah dibuat recommend_games dan memasukkan input berupa user_id, model yang telah dibuat menggunakan RecommenderNet, dan jumlah rekomendasi yang diinginkan
"""

def recommend_games(user_id, model, num_recommendations=3):
    # Encode user_id
    if user_id not in user_to_user_encoded:
        raise ValueError(f"User ID {user_id} tidak ditemukan di user_to_user_encoded.")

    user_idx = user_to_user_encoded[user_id]

    # Mendapatkan vektor embedding untuk user
    user_embedding = model.user_embedding(np.array([user_idx]))

    # Mendapatkan vektor embedding untuk semua games
    game_embeddings = model.games_embedding.embeddings.numpy()

    # Menghitung kesamaan (dot product) antara user embedding dan semua game embeddings
    scores = np.dot(game_embeddings, user_embedding.numpy().T).flatten()

    # Mendapatkan indeks game dengan skor tertinggi
    recommended_game_indices = np.argsort(scores)[-num_recommendations:][::-1]

    # Mendapatkan game_id dari indeks
    recommended_game_ids = [games_encoded_to_games[idx] for idx in recommended_game_indices]

    # Mendapatkan judul game dari game_id
    recommended_games = games_merge[games_merge['app_id'].isin(recommended_game_ids)]

    return recommended_games[['app_id', 'title', 'tags']]

def get_user_recommended_games(user_id):
    user_games = recommendations_merge[(recommendations_merge['user_id'] == user_id) & (recommendations_merge['is_recommended'] == True)]
    return user_games[['app_id', 'title', 'tags']]

# Mengambil sampel user
user_id = recommendations_merge['user_id'].sample(1).iloc[0]

# Mendapatkan rekomendasi games
try:
    recommended_games = recommend_games(user_id, model, num_recommendations=3)
    user_recommended_games = get_user_recommended_games(user_id)

    # Menampilkan hasil dengan DataFrame
    print(f"Game yang direkomendasikan oleh user dengan user_id={user_id}:")
    display(user_recommended_games)

    print(f"\nRekomendasi games untuk user dengan user_id={user_id}:")
    display(recommended_games)

except ValueError as e:
    print(e)

"""Tabel di atas menunjukkan tabel hasil dari rekomendasi collaborative"""